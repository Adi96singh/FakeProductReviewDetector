{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd2d8b8e-0f7e-48f3-b9b1-0497b1a920f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2585985837.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install pandas scikit-learn joblib\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install pandas scikit-learn joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a9d862e-b417-4de6-b78e-e4fe11ffc840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.1.2-cp313-cp313-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\singh\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\singh\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp313-cp313-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 4.2/11.5 MB 21.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.5/11.5 MB 20.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.6/11.5 MB 10.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.7/11.5 MB 10.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.2/11.5 MB 9.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.0/11.5 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 7.9 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.5.2-cp313-cp313-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.0 MB 1.3 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.8/11.0 MB 1.4 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.0/11.0 MB 1.3 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 1.3 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.8/11.0 MB 1.4 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.1/11.0 MB 1.4 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 2.4/11.0 MB 1.5 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 1.5 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 3.4/11.0 MB 1.6 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 3.7/11.0 MB 1.6 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.9/11.0 MB 1.6 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.2/11.0 MB 1.6 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 5.0/11.0 MB 1.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 5.5/11.0 MB 1.6 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 5.8/11.0 MB 1.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 6.8/11.0 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 7.3/11.0 MB 1.7 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.6/11.0 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 8.4/11.0 MB 1.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 8.9/11.0 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.2/11.0 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 2.0 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading numpy-2.1.2-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.6 MB 2.1 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.8/12.6 MB 1.4 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 1.0/12.6 MB 1.3 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 1.3 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 1.3 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 1.2 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 2.4/12.6 MB 1.4 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 2.9/12.6 MB 1.6 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 3.4/12.6 MB 1.7 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 3.9/12.6 MB 1.8 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 4.5/12.6 MB 1.8 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.7/12.6 MB 1.8 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 5.2/12.6 MB 1.8 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 1.8 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 5.8/12.6 MB 1.7 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 6.0/12.6 MB 1.6 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 6.0/12.6 MB 1.6 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 6.6/12.6 MB 1.6 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 6.8/12.6 MB 1.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 7.1/12.6 MB 1.6 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 7.6/12.6 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 7.9/12.6 MB 1.5 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 8.4/12.6 MB 1.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 9.4/12.6 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.7/12.6 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.7/12.6 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 10.0/12.6 MB 1.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 10.5/12.6 MB 1.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 10.5/12.6 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 1.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 11.0/12.6 MB 1.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 11.3/12.6 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.5/12.6 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.8/12.6 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.6 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 1.5 MB/s eta 0:00:00\n",
      "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Downloading scipy-1.14.1-cp313-cp313-win_amd64.whl (44.5 MB)\n",
      "   ---------------------------------------- 0.0/44.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/44.5 MB 2.9 MB/s eta 0:00:15\n",
      "    --------------------------------------- 1.0/44.5 MB 3.2 MB/s eta 0:00:14\n",
      "   - -------------------------------------- 1.6/44.5 MB 2.8 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 1.6/44.5 MB 2.8 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 1.8/44.5 MB 1.8 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 2.1/44.5 MB 1.7 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 2.6/44.5 MB 1.7 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 3.1/44.5 MB 1.8 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 3.4/44.5 MB 1.9 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 3.7/44.5 MB 1.8 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 4.2/44.5 MB 1.9 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 4.5/44.5 MB 1.9 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 5.0/44.5 MB 1.8 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 5.2/44.5 MB 1.8 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 5.5/44.5 MB 1.7 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 5.5/44.5 MB 1.7 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 5.8/44.5 MB 1.7 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 6.0/44.5 MB 1.6 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 6.3/44.5 MB 1.6 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 6.8/44.5 MB 1.6 MB/s eta 0:00:23\n",
      "   ------ --------------------------------- 7.3/44.5 MB 1.7 MB/s eta 0:00:23\n",
      "   ------- -------------------------------- 7.9/44.5 MB 1.7 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 8.7/44.5 MB 1.8 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 9.2/44.5 MB 1.8 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 9.7/44.5 MB 1.9 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 10.0/44.5 MB 1.9 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 10.2/44.5 MB 1.9 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 10.5/44.5 MB 1.9 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 11.0/44.5 MB 1.8 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 11.3/44.5 MB 1.8 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 11.3/44.5 MB 1.8 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 11.5/44.5 MB 1.7 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 11.8/44.5 MB 1.7 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 12.1/44.5 MB 1.7 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 12.3/44.5 MB 1.7 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 12.6/44.5 MB 1.7 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 13.1/44.5 MB 1.7 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 13.4/44.5 MB 1.7 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 13.9/44.5 MB 1.7 MB/s eta 0:00:18\n",
      "   ------------ --------------------------- 14.2/44.5 MB 1.7 MB/s eta 0:00:18\n",
      "   ------------ --------------------------- 14.4/44.5 MB 1.7 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 14.7/44.5 MB 1.7 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 14.9/44.5 MB 1.7 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 15.5/44.5 MB 1.7 MB/s eta 0:00:18\n",
      "   -------------- ------------------------- 16.0/44.5 MB 1.7 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 16.3/44.5 MB 1.7 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 16.8/44.5 MB 1.7 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 17.3/44.5 MB 1.7 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 17.6/44.5 MB 1.7 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 18.1/44.5 MB 1.7 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 18.6/44.5 MB 1.8 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 19.4/44.5 MB 1.8 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 19.7/44.5 MB 1.8 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 19.9/44.5 MB 1.8 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 20.4/44.5 MB 1.8 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 20.7/44.5 MB 1.8 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 21.2/44.5 MB 1.8 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 21.5/44.5 MB 1.8 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 22.3/44.5 MB 1.8 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 22.5/44.5 MB 1.8 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 23.1/44.5 MB 1.8 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 23.3/44.5 MB 1.8 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 23.9/44.5 MB 1.8 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 24.4/44.5 MB 1.8 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 24.6/44.5 MB 1.8 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 24.9/44.5 MB 1.8 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 25.2/44.5 MB 1.8 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 25.4/44.5 MB 1.8 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 25.7/44.5 MB 1.8 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 26.0/44.5 MB 1.8 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 26.5/44.5 MB 1.8 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 26.7/44.5 MB 1.8 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 27.3/44.5 MB 1.8 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 27.8/44.5 MB 1.8 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 28.3/44.5 MB 1.8 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 29.1/44.5 MB 1.8 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 29.6/44.5 MB 1.8 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 29.9/44.5 MB 1.8 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 29.9/44.5 MB 1.8 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 30.1/44.5 MB 1.8 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 30.7/44.5 MB 1.8 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 30.9/44.5 MB 1.8 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 31.5/44.5 MB 1.8 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 31.5/44.5 MB 1.8 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 32.0/44.5 MB 1.8 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 32.5/44.5 MB 1.8 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 32.8/44.5 MB 1.8 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 33.0/44.5 MB 1.8 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 33.3/44.5 MB 1.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 33.8/44.5 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 34.1/44.5 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 34.3/44.5 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 34.6/44.5 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 34.9/44.5 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 34.9/44.5 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 35.1/44.5 MB 1.7 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 35.4/44.5 MB 1.7 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 35.7/44.5 MB 1.7 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 36.2/44.5 MB 1.7 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 36.7/44.5 MB 1.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 37.2/44.5 MB 1.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 37.7/44.5 MB 1.8 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 38.0/44.5 MB 1.8 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 38.3/44.5 MB 1.8 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 38.5/44.5 MB 1.8 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 38.8/44.5 MB 1.8 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 39.3/44.5 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 39.8/44.5 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 39.8/44.5 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 40.6/44.5 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 41.4/44.5 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 42.2/44.5 MB 1.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 43.0/44.5 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.5/44.5 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.3/44.5 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.5/44.5 MB 1.8 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, threadpoolctl, numpy, joblib, scipy, pandas, scikit-learn\n",
      "Successfully installed joblib-1.4.2 numpy-2.1.2 pandas-2.2.3 pytz-2024.2 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0 tzdata-2024.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b4f7bff-4e15-42d9-8999-3d9e75a4e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('fake_reviews_dataset.csv')\n",
    "\n",
    "# Label encoding (CG -> 0, OR -> 1)\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "# TF-IDF Vectorization of review text\n",
    "tfidf = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X = tfidf.fit_transform(df['text'])\n",
    "\n",
    "# Combine text features with rating\n",
    "X_combined = pd.DataFrame(X.toarray())\n",
    "X_combined['rating'] = df['rating']\n",
    "\n",
    "# Target variable\n",
    "y = df['label']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01f60823-efb8-4f30-9abc-c5203195ca17",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Train a RandomForest model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Save the model and the TF-IDF vectorizer for later use\u001b[39;00m\n\u001b[0;32m      8\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfake_review_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:363\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 363\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    545\u001b[0m ):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:469\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set or check the `feature_names_in_` attribute.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m       should set `reset=False`.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset:\n\u001b[1;32m--> 469\u001b[0m     feature_names_in \u001b[38;5;241m=\u001b[39m \u001b[43m_get_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature_names_in \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    471\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names_in_ \u001b[38;5;241m=\u001b[39m feature_names_in\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2279\u001b[0m, in \u001b[0;36m_get_feature_names\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m   2277\u001b[0m \u001b[38;5;66;03m# mixed type of string and non-string is not supported\u001b[39;00m\n\u001b[0;32m   2278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m types:\n\u001b[1;32m-> 2279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   2280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names are only supported if all input features have string names, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut your input has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as feature name / column name types. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you want feature names to be stored and validated, you must convert \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthem all to strings, by using X.columns = X.columns.astype(str) for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample. Otherwise you can remove feature / column names from your input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata, or convert them all to a non-string data type.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2286\u001b[0m     )\n\u001b[0;32m   2288\u001b[0m \u001b[38;5;66;03m# Only feature names of all strings are supported\u001b[39;00m\n\u001b[0;32m   2289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m types[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train a RandomForest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model and the TF-IDF vectorizer for later use\n",
    "joblib.dump(model, 'fake_review_model.pkl')\n",
    "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8137c75-3043-4618-a6ab-a0e8664ebc84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "# Convert column names of X_combined to strings to avoid the error\n",
    "X_combined.columns = X_combined.columns.astype(str)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a RandomForest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model and the TF-IDF vectorizer for later use\n",
    "joblib.dump(model, 'fake_review_model.pkl')\n",
    "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "702cf788-3c2b-4a46-b759-a3a9791f95d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the saved RandomForest model and TF-IDF vectorizer\n",
    "model = joblib.load('fake_review_model.pkl')\n",
    "tfidf_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "998b82b4-7ffc-40e5-bca3-0d588b3c5c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This product is amazing! I love it.\n",
      "Prediction: Genuine\n"
     ]
    }
   ],
   "source": [
    "# Example review text\n",
    "test_review = \"This product is amazing! I love it.\"\n",
    "\n",
    "# Step 1: Vectorize the input review (1000 features)\n",
    "review_vectorized = tfidf_vectorizer.transform([test_review])\n",
    "\n",
    "# Step 2: Convert to DataFrame to match the training format\n",
    "import pandas as pd\n",
    "review_vectorized_df = pd.DataFrame(review_vectorized.toarray())\n",
    "\n",
    "# Step 3: Add a dummy 'rating' column (set to a reasonable value, e.g., 5)\n",
    "review_vectorized_df['rating'] = 5  # Add the rating column\n",
    "\n",
    "# Step 4: Convert all feature names to strings to avoid the error\n",
    "review_vectorized_df.columns = review_vectorized_df.columns.astype(str)\n",
    "\n",
    "# Step 5: Get model prediction (0 = Genuine, 1 = Fake)\n",
    "prediction = model.predict(review_vectorized_df)[0]\n",
    "\n",
    "# Step 6: Output the result\n",
    "result = 'Fake' if prediction == 1 else 'Genuine'\n",
    "print(f\"Review: {test_review}\\nPrediction: {result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb15bb11-7e6b-4cbd-9fd1-8235096cbcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This product is amazing! I love it.\n",
      "Prediction: Genuine\n",
      "\n",
      "Review: Terrible product, not worth the money!\n",
      "Prediction: Fake\n",
      "\n",
      "Review: Best product I've ever used. Highly recommend.\n",
      "Prediction: Genuine\n",
      "\n",
      "Review: This review seems very fake, don't trust it.\n",
      "Prediction: Fake\n",
      "\n",
      "Review: The delivery was delayed but the product is worth it.\n",
      "Prediction: Fake\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of reviews for testing\n",
    "test_reviews = [\n",
    "    \"This product is amazing! I love it.\",\n",
    "    \"Terrible product, not worth the money!\",\n",
    "    \"Best product I've ever used. Highly recommend.\",\n",
    "    \"This review seems very fake, don't trust it.\",\n",
    "    \"The delivery was delayed but the product is worth it.\"\n",
    "]\n",
    "\n",
    "# Step 1: Vectorize the reviews (1000 features)\n",
    "reviews_vectorized = tfidf_vectorizer.transform(test_reviews)\n",
    "\n",
    "# Step 2: Convert to DataFrame to match the training format\n",
    "reviews_vectorized_df = pd.DataFrame(reviews_vectorized.toarray())\n",
    "\n",
    "# Step 3: Add a dummy 'rating' column (set to a reasonable value, e.g., 5)\n",
    "reviews_vectorized_df['rating'] = 5  # Add the rating column\n",
    "\n",
    "# Step 4: Convert all feature names to strings to avoid the error\n",
    "reviews_vectorized_df.columns = reviews_vectorized_df.columns.astype(str)\n",
    "\n",
    "# Step 5: Get predictions for each review\n",
    "predictions = model.predict(reviews_vectorized_df)\n",
    "\n",
    "# Step 6: Display results for each review\n",
    "for review, pred in zip(test_reviews, predictions):\n",
    "    result = 'Fake' if pred == 1 else 'Genuine'\n",
    "    print(f\"Review: {review}\\nPrediction: {result}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84b8320c-c9da-458b-853f-d23ba08bbdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy on Test Data: 81.14%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Model Accuracy on Test Data: {accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36834ae8-c69e-41fe-9849-c50f945b2731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
